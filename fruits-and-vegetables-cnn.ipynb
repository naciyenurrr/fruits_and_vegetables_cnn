{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3173719,"sourceType":"datasetVersion","datasetId":952827}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/naciyenur/fruits-and-vegetables-cnn?scriptVersionId=264200844\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\n\ncount = 0\nfor dirname, _, filenames in os.walk('/kaggle/input/fruit-and-vegetable-image-recognition'):\n    count += len(filenames)\nprint(f\"Toplam dosya sayısı: {count}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:05.893946Z","iopub.execute_input":"2025-09-26T14:32:05.89423Z","iopub.status.idle":"2025-09-26T14:32:09.050079Z","shell.execute_reply.started":"2025-09-26T14:32:05.894193Z","shell.execute_reply":"2025-09-26T14:32:09.04922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom collections import Counter\n\n# Dataset klasörü\ndataset_path = '/kaggle/input/fruit-and-vegetable-image-recognition'\n\n# Tüm dosya uzantılarını toplama\nextensions = []\nfor dirname, _, filenames in os.walk(dataset_path):\n    for filename in filenames:\n        ext = os.path.splitext(filename)[1].lower()  # .jpg, .jpeg, .png gibi\n        extensions.append(ext)\n\n# Kaç tane her uzantı var?\next_counts = Counter(extensions)\nprint(\"Dosya uzantıları ve sayıları:\")\nfor ext, count in ext_counts.items():\n    print(f\"{ext}: {count}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:10.138922Z","iopub.execute_input":"2025-09-26T14:32:10.139179Z","iopub.status.idle":"2025-09-26T14:32:10.222899Z","shell.execute_reply.started":"2025-09-26T14:32:10.139159Z","shell.execute_reply":"2025-09-26T14:32:10.222106Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****VERİ ÖN İŞLEME AŞAMASI****","metadata":{}},{"cell_type":"code","source":"# Gerekli kütüphanelerin import edilmesi\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:12.742912Z","iopub.execute_input":"2025-09-26T14:32:12.743441Z","iopub.status.idle":"2025-09-26T14:32:12.747831Z","shell.execute_reply.started":"2025-09-26T14:32:12.74342Z","shell.execute_reply":"2025-09-26T14:32:12.746987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_path = '/kaggle/input/fruit-and-vegetable-image-recognition'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:14.472573Z","iopub.execute_input":"2025-09-26T14:32:14.472919Z","iopub.status.idle":"2025-09-26T14:32:14.476549Z","shell.execute_reply.started":"2025-09-26T14:32:14.472895Z","shell.execute_reply":"2025-09-26T14:32:14.475751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dosyaları dataframe aktarıyoruz\nfilepaths = []\nlabels = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:16.248918Z","iopub.execute_input":"2025-09-26T14:32:16.249185Z","iopub.status.idle":"2025-09-26T14:32:16.252968Z","shell.execute_reply.started":"2025-09-26T14:32:16.249164Z","shell.execute_reply":"2025-09-26T14:32:16.252218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for root, _, files in os.walk(dataset_path):\n    for file in files:\n        filepaths.append(os.path.join(root, file))\n        labels.append(os.path.basename(root))  \n\ndf = pd.DataFrame({'filepath': filepaths, 'label': labels})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:16.581138Z","iopub.execute_input":"2025-09-26T14:32:16.581342Z","iopub.status.idle":"2025-09-26T14:32:16.668098Z","shell.execute_reply.started":"2025-09-26T14:32:16.581328Z","shell.execute_reply":"2025-09-26T14:32:16.667552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" df.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:18.147128Z","iopub.execute_input":"2025-09-26T14:32:18.147746Z","iopub.status.idle":"2025-09-26T14:32:18.154979Z","shell.execute_reply.started":"2025-09-26T14:32:18.147723Z","shell.execute_reply":"2025-09-26T14:32:18.15417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"label\"].value_counts()\n#hangi sınıfta kaç tane görüntü var görüyoruz ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:18.422288Z","iopub.execute_input":"2025-09-26T14:32:18.422553Z","iopub.status.idle":"2025-09-26T14:32:18.429696Z","shell.execute_reply.started":"2025-09-26T14:32:18.422533Z","shell.execute_reply":"2025-09-26T14:32:18.429055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:20.341245Z","iopub.execute_input":"2025-09-26T14:32:20.341544Z","iopub.status.idle":"2025-09-26T14:32:20.357148Z","shell.execute_reply.started":"2025-09-26T14:32:20.341522Z","shell.execute_reply":"2025-09-26T14:32:20.356194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n# veri görselleştirme kütüphaneleri","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:20.537582Z","iopub.execute_input":"2025-09-26T14:32:20.537891Z","iopub.status.idle":"2025-09-26T14:32:20.541602Z","shell.execute_reply.started":"2025-09-26T14:32:20.53787Z","shell.execute_reply":"2025-09-26T14:32:20.540894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(y='label', data=df, order=df['label'].value_counts().index)\nplt.title('Sınıf Dağılımı')\nplt.xlabel('Görüntü Sayısı')\nplt.ylabel('Sınıf')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:23.616017Z","iopub.execute_input":"2025-09-26T14:32:23.616768Z","iopub.status.idle":"2025-09-26T14:32:23.966163Z","shell.execute_reply.started":"2025-09-26T14:32:23.616744Z","shell.execute_reply":"2025-09-26T14:32:23.965424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"HER GÖRSELİN BOYUTU VE FARKINI İNCELEMEMİZ GEREKİYOR","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n#Image sınıfı, resim dosyalarını açmak, oluşturmak ve üzerinde işlem yapmak için kullanılır.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:25.722139Z","iopub.execute_input":"2025-09-26T14:32:25.722816Z","iopub.status.idle":"2025-09-26T14:32:25.726212Z","shell.execute_reply.started":"2025-09-26T14:32:25.722794Z","shell.execute_reply":"2025-09-26T14:32:25.725441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"widths = []\nheights = []\nformats = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:25.897811Z","iopub.execute_input":"2025-09-26T14:32:25.898074Z","iopub.status.idle":"2025-09-26T14:32:25.902193Z","shell.execute_reply.started":"2025-09-26T14:32:25.898055Z","shell.execute_reply":"2025-09-26T14:32:25.901466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for path in df['filepath'][:1000]: \n    img = Image.open(path)\n    widths.append(img.width)\n    heights.append(img.height)\n    formats.append(img.format)\n    #1000 tane örnek alıyoruz ve img nesnesi kullanarak inceliyoruz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:28.372768Z","iopub.execute_input":"2025-09-26T14:32:28.373379Z","iopub.status.idle":"2025-09-26T14:32:29.603721Z","shell.execute_reply.started":"2025-09-26T14:32:28.373356Z","shell.execute_reply":"2025-09-26T14:32:29.602961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.histplot(widths, kde=True)\nplt.title('Görüntü Genişlik Dağılımı')\n\nplt.subplot(1,2,2)\nsns.histplot(heights, kde=True)\nplt.title('Görüntü Yükseklik Dağılımı')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:29.604884Z","iopub.execute_input":"2025-09-26T14:32:29.605113Z","iopub.status.idle":"2025-09-26T14:32:30.082104Z","shell.execute_reply.started":"2025-09-26T14:32:29.605081Z","shell.execute_reply":"2025-09-26T14:32:30.08131Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Her iki histogram da sağa doğru çarpık (skewed to the right) bir dağılım gösteriyor. Bu, veri setindeki görüntülerin çoğunluğunun belirli bir değer aralığında toplandığını, ancak az sayıda görüntünün çok daha büyük genişlik veya yükseklik değerlerine sahip olduğunu ifade eder.","metadata":{}},{"cell_type":"code","source":"pd.Series(formats).value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:33.614231Z","iopub.execute_input":"2025-09-26T14:32:33.614503Z","iopub.status.idle":"2025-09-26T14:32:33.621441Z","shell.execute_reply.started":"2025-09-26T14:32:33.614484Z","shell.execute_reply":"2025-09-26T14:32:33.620639Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"os.path ile dosya uzantısına bakıyoruz ama Image kütüphanesi görüntüyü açıp gerçek format bilgisini döndürüyor.","metadata":{}},{"cell_type":"code","source":"import random\nclasses = df['label'].unique()\nplt.figure(figsize=(15,8))\n\nfor i, cls in enumerate(classes[:6]):  \n    sample_path = random.choice(df[df['label']==cls]['filepath'].tolist())\n    img = Image.open(sample_path)\n    \n    plt.subplot(2,3,i+1)\n    plt.imshow(img)\n    plt.title(cls)\n    plt.axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:35.531252Z","iopub.execute_input":"2025-09-26T14:32:35.531935Z","iopub.status.idle":"2025-09-26T14:32:37.971844Z","shell.execute_reply.started":"2025-09-26T14:32:35.531914Z","shell.execute_reply":"2025-09-26T14:32:37.971009Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ilk 6 sınıftan rastgele resim çıkıyor ve bu sayede çeşitliliği görmüş oluyoruz.","metadata":{}},{"cell_type":"code","source":"#dosya uzunatıları\npd.Series([os.path.splitext(p)[1].lower() for p in df['filepath']]).value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:38.072973Z","iopub.execute_input":"2025-09-26T14:32:38.073671Z","iopub.status.idle":"2025-09-26T14:32:38.083589Z","shell.execute_reply.started":"2025-09-26T14:32:38.073651Z","shell.execute_reply":"2025-09-26T14:32:38.082895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aspect_ratios = [w/h for w,h in zip(widths, heights)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:38.389526Z","iopub.execute_input":"2025-09-26T14:32:38.390063Z","iopub.status.idle":"2025-09-26T14:32:38.393529Z","shell.execute_reply.started":"2025-09-26T14:32:38.390041Z","shell.execute_reply":"2025-09-26T14:32:38.392881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(aspect_ratios, bins=30)\nplt.title(\"Aspect Ratio Dağılımı\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:43.349005Z","iopub.execute_input":"2025-09-26T14:32:43.349266Z","iopub.status.idle":"2025-09-26T14:32:43.515572Z","shell.execute_reply.started":"2025-09-26T14:32:43.349247Z","shell.execute_reply":"2025-09-26T14:32:43.514946Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Görsellerin çoğu .jpg bazıları ise .jpeg ve .png. Modelimiz için bunları tek formata dönüştürücez. jpeg -> .jpg olarak değiştirebiliriz. .png görsellierini de .jpg'ye PIL ile kolayca dönüştürebiliriz. Böylece ImageDataGenerator veya PyTorch/TF Dataset pipeline’ında hata riskini azaltırız.","metadata":{}},{"cell_type":"code","source":"import shutil\n\noutput_dir = '/kaggle/working/fruit_veg_dataset'\nos.makedirs(output_dir, exist_ok=True)\n\nnew_filepaths = []\n\nfor idx, row in df.iterrows():\n    path = row['filepath']\n    ext = os.path.splitext(path)[1].lower()\n    \n    # Görseli aç ve RGB’ye çevir\n    img = Image.open(path).convert('RGB')\n    \n    # Yeni kaydetme yolu\n    new_path = os.path.join(output_dir, f\"{idx}.jpg\")\n    img.save(new_path)\n    new_filepaths.append(new_path)\n\n# DataFrame’i güncelle\ndf['filepath'] = new_filepaths\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:32:46.700972Z","iopub.execute_input":"2025-09-26T14:32:46.701552Z","iopub.status.idle":"2025-09-26T14:35:04.410273Z","shell.execute_reply.started":"2025-09-26T14:32:46.701532Z","shell.execute_reply":"2025-09-26T14:35:04.409651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for idx, row in df.iterrows():\n    path = row['filepath']\n    ext = os.path.splitext(path)[1].lower()\n    if ext in ['.png', '.jpeg']:\n        img = Image.open(path).convert('RGB')\n        new_path = os.path.splitext(path)[0] + '.jpg'\n        img.save(new_path)\n        df.at[idx, 'filepath'] = new_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:04.411573Z","iopub.execute_input":"2025-09-26T14:35:04.412008Z","iopub.status.idle":"2025-09-26T14:35:04.556117Z","shell.execute_reply.started":"2025-09-26T14:35:04.411987Z","shell.execute_reply":"2025-09-26T14:35:04.555554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.Series([os.path.splitext(p)[1].lower() for p in df['filepath']]).value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:04.556849Z","iopub.execute_input":"2025-09-26T14:35:04.557052Z","iopub.status.idle":"2025-09-26T14:35:04.566888Z","shell.execute_reply.started":"2025-09-26T14:35:04.557035Z","shell.execute_reply":"2025-09-26T14:35:04.566227Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"şimdi tüm verilerimiz .jpg oldu. İşlemlerimize devam edebiliriz.","metadata":{}},{"cell_type":"markdown","source":"****Train / Validation / Test setlerine ayırma****\nBunun için sklearn kütüphanesini kullanıyoruz.\n","metadata":{}},{"cell_type":"code","source":"\ntrain_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n\n# burada stratify kullanrak her sınıfın oranını koruyoruz ki modelimiz doğru sonuçlar versin.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:34.632471Z","iopub.execute_input":"2025-09-26T14:35:34.633162Z","iopub.status.idle":"2025-09-26T14:35:34.645624Z","shell.execute_reply.started":"2025-09-26T14:35:34.633141Z","shell.execute_reply":"2025-09-26T14:35:34.645036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:35.767855Z","iopub.execute_input":"2025-09-26T14:35:35.768131Z","iopub.status.idle":"2025-09-26T14:35:35.77433Z","shell.execute_reply.started":"2025-09-26T14:35:35.768094Z","shell.execute_reply":"2025-09-26T14:35:35.773585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_size = (128, 128)   # resimleri yeniden boyutlandırma\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:37.517399Z","iopub.execute_input":"2025-09-26T14:35:37.517669Z","iopub.status.idle":"2025-09-26T14:35:37.521326Z","shell.execute_reply.started":"2025-09-26T14:35:37.517649Z","shell.execute_reply":"2025-09-26T14:35:37.520701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:38.272514Z","iopub.execute_input":"2025-09-26T14:35:38.272788Z","iopub.status.idle":"2025-09-26T14:35:38.276178Z","shell.execute_reply.started":"2025-09-26T14:35:38.272768Z","shell.execute_reply":"2025-09-26T14:35:38.275502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimg_size = (128, 128)\nbatch_size = 32\n\ndatagen = ImageDataGenerator(rescale=1./255)\n# tüm görselleri 0-255 aralığında 0-1 aralığına ölçeklendirdik. bu işlem modelin daha hızlı ve \n# stabil öğrenmesi için standart bir ön işlmeme adımıdır.\n\n#eğitim verileri\ntrain_gen = datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"   # çok sınıflı sınıflandırma\n)\n#doğrulama verileri\nval_gen = datagen.flow_from_dataframe(\n    dataframe=val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)\n#test verileri\ntest_gen = datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:39.103046Z","iopub.execute_input":"2025-09-26T14:35:39.103698Z","iopub.status.idle":"2025-09-26T14:35:39.144399Z","shell.execute_reply.started":"2025-09-26T14:35:39.103657Z","shell.execute_reply":"2025-09-26T14:35:39.143713Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"train seti 3060 görsel buldu ve toplamda 36 farklı sınıfa dağıttı.\nvalidation setinde 382 görsel bulundu ve toplamda 36 farklı sınıfa dağıttı.\ntest setinde 383 görsel bulundu ve toplamda 36 farklı sınıfa dağıttı.","metadata":{}},{"cell_type":"code","source":"# Artık elimizde 3 tane generator var (train_gen, val_gen, test_gen), bunları oluşturacağmız CNN modeline verebiliriz.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:42.366766Z","iopub.execute_input":"2025-09-26T14:35:42.36704Z","iopub.status.idle":"2025-09-26T14:35:42.370889Z","shell.execute_reply.started":"2025-09-26T14:35:42.36702Z","shell.execute_reply":"2025-09-26T14:35:42.370138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"CNN (Convolutional Neural Network) dediğimiz yapı görsellerden otomatik özellik çıkarma işini yapar.\nŞu parçaları içerir:\n\n***Conv Katmanı (Convolutional Layer):***\n\nGörsellerde kenar, köşe, renk geçişi gibi özellikleri filtrelerle yakalar.\n\nÖrn: layers.Conv2D(32, (3,3), activation='relu')\n→ 32 tane 3x3 filtre uygular, aktivasyon fonksiyonu ReLU.\n\n***Pooling Katmanı (MaxPooling):***\n\nGörselin boyutunu küçültür ama en önemli bilgileri korur.\n\nÖrn: layers.MaxPooling2D((2,2))\n→ 2x2’lik pencereden maksimum değeri alır.\n\n***Dropout Katmanı:***\n\nOverfitting’i önlemek için bazı nöronları rastgele kapatır.\n\nÖrn: layers.Dropout(0.5) → %50’sini kapatır.\n\nFlatten + Dense (Fully Connected):\n\nÖzellikleri düzleştirip (Flatten) klasik sinir ağına verir.\n\nDense(128, activation='relu') → gizli katman.\n\nDense(num_classes, activation='softmax') → çıktı katmanı, sınıfları tahmin eder.\n","metadata":{}},{"cell_type":"code","source":"num_classes = len(train_gen.class_indices)\n\nfrom tensorflow.keras import layers, models\n\nmodel = models.Sequential([\n    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),#görsellerden özellik çıkarımı yapıyor\n    layers.MaxPooling2D((2,2)), # Görselleri küçültüp önemli özellikleri koruyor.\n\n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    layers.Flatten(),# flatten tek boyutlu vektöre çeviriyor dense katmanına bağlamk için\n    layers.Dropout(0.5), #Modelin aşırı öğrenmesini (overfitting) önlemek için bazı nöronları rastgele kapatıyor. Eğer overfitting görürsek dropout oranını arttırabiliriz.\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')  # çıktı katmanı\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:44.536012Z","iopub.execute_input":"2025-09-26T14:35:44.536726Z","iopub.status.idle":"2025-09-26T14:35:44.588226Z","shell.execute_reply.started":"2025-09-26T14:35:44.536702Z","shell.execute_reply":"2025-09-26T14:35:44.587481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#modeli derleme \nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:47.075081Z","iopub.execute_input":"2025-09-26T14:35:47.075627Z","iopub.status.idle":"2025-09-26T14:35:47.083631Z","shell.execute_reply.started":"2025-09-26T14:35:47.075601Z","shell.execute_reply":"2025-09-26T14:35:47.083063Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"modeli eğitme","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_gen,\n    epochs=20,\n    validation_data=val_gen\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:35:49.489814Z","iopub.execute_input":"2025-09-26T14:35:49.490084Z","iopub.status.idle":"2025-09-26T14:47:40.577149Z","shell.execute_reply.started":"2025-09-26T14:35:49.490058Z","shell.execute_reply":"2025-09-26T14:47:40.576571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.show()\n\n# Loss\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:47:47.255961Z","iopub.execute_input":"2025-09-26T14:47:47.25665Z","iopub.status.idle":"2025-09-26T14:47:47.51228Z","shell.execute_reply.started":"2025-09-26T14:47:47.256627Z","shell.execute_reply":"2025-09-26T14:47:47.511646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"modelimiz aşırı öğrenmeye uğradı yani eğitim doğruluğu hızla artıyor ama doğrulama doğruluğu 55-60 civarında takılı kalıyor. Validation loss ise özellikle 5. epoch dan sonra artmaya başlıyor. Modelimiz sıfırdan öğrendiği için düşük bir doğruluk kazandı. Çünkü dataset karmaşık ve çok sınıflı. EfficientNet / MobileNet / ResNet gibi hazır modeller kullanamyı deneyelim.","metadata":{}},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_gen)\nprint(f\"Test Accuracy: {test_acc:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:47:54.390541Z","iopub.execute_input":"2025-09-26T14:47:54.390819Z","iopub.status.idle":"2025-09-26T14:47:59.329176Z","shell.execute_reply.started":"2025-09-26T14:47:54.390797Z","shell.execute_reply":"2025-09-26T14:47:59.328597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:02.62893Z","iopub.execute_input":"2025-09-26T14:48:02.629585Z","iopub.status.idle":"2025-09-26T14:48:02.633087Z","shell.execute_reply.started":"2025-09-26T14:48:02.62956Z","shell.execute_reply":"2025-09-26T14:48:02.632416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_size = (128, 128)\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:21.253707Z","iopub.execute_input":"2025-09-26T14:48:21.25397Z","iopub.status.idle":"2025-09-26T14:48:21.257598Z","shell.execute_reply.started":"2025-09-26T14:48:21.25395Z","shell.execute_reply":"2025-09-26T14:48:21.256909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train için augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:21.857174Z","iopub.execute_input":"2025-09-26T14:48:21.857384Z","iopub.status.idle":"2025-09-26T14:48:21.861302Z","shell.execute_reply.started":"2025-09-26T14:48:21.857368Z","shell.execute_reply":"2025-09-26T14:48:21.860554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Validation & Test için sadece normalize\nval_test_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:23.9776Z","iopub.execute_input":"2025-09-26T14:48:23.977884Z","iopub.status.idle":"2025-09-26T14:48:23.98171Z","shell.execute_reply.started":"2025-09-26T14:48:23.977863Z","shell.execute_reply":"2025-09-26T14:48:23.980942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DataFrame üzerinden okuma\ntrain_gen = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)\nval_gen = val_test_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)\n\ntest_gen = val_test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:26.478574Z","iopub.execute_input":"2025-09-26T14:48:26.478888Z","iopub.status.idle":"2025-09-26T14:48:26.521193Z","shell.execute_reply.started":"2025-09-26T14:48:26.47885Z","shell.execute_reply":"2025-09-26T14:48:26.520646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(train_gen.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:28.651403Z","iopub.execute_input":"2025-09-26T14:48:28.651662Z","iopub.status.idle":"2025-09-26T14:48:28.655088Z","shell.execute_reply.started":"2025-09-26T14:48:28.651643Z","shell.execute_reply":"2025-09-26T14:48:28.654296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(128,128,3))\nbase_model.trainable = False   # önce dondur\n\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dropout(0.4),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dropout(0.3),\n    layers.Dense(num_classes, activation=\"softmax\")\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:30.136836Z","iopub.execute_input":"2025-09-26T14:48:30.137097Z","iopub.status.idle":"2025-09-26T14:48:30.837962Z","shell.execute_reply.started":"2025-09-26T14:48:30.137072Z","shell.execute_reply":"2025-09-26T14:48:30.837415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# İlk Eğitim (Feature Extraction)\nhistory = model.fit(\n    train_gen,\n    epochs=15,\n    validation_data=val_gen\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:48:32.723392Z","iopub.execute_input":"2025-09-26T14:48:32.72365Z","iopub.status.idle":"2025-09-26T14:59:34.544054Z","shell.execute_reply.started":"2025-09-26T14:48:32.72363Z","shell.execute_reply":"2025-09-26T14:59:34.543512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#fine turning\nbase_model.trainable = True\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-5),  # küçük LR\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory_fine = model.fit(\n    train_gen,\n    epochs=10,\n    validation_data=val_gen\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T14:59:52.137264Z","iopub.execute_input":"2025-09-26T14:59:52.137972Z","iopub.status.idle":"2025-09-26T15:08:23.353139Z","shell.execute_reply.started":"2025-09-26T14:59:52.137947Z","shell.execute_reply":"2025-09-26T15:08:23.352416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss, acc = model.evaluate(test_gen)\nprint(\"Test Accuracy:\", acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T15:08:27.505237Z","iopub.execute_input":"2025-09-26T15:08:27.50551Z","iopub.status.idle":"2025-09-26T15:08:33.204564Z","shell.execute_reply.started":"2025-09-26T15:08:27.50549Z","shell.execute_reply":"2025-09-26T15:08:33.204009Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"***modelimizin doğruluğunu arttırmak için data augmentation'u zenginleştirebiliriz***","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:45:23.713199Z","iopub.execute_input":"2025-09-26T16:45:23.713462Z","iopub.status.idle":"2025-09-26T16:45:23.717116Z","shell.execute_reply.started":"2025-09-26T16:45:23.713442Z","shell.execute_reply":"2025-09-26T16:45:23.71649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_size = (128, 128)\nbatch_size = 32\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    zoom_range=0.3,\n    brightness_range=[0.7, 1.3],\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode=\"nearest\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:45:25.236552Z","iopub.execute_input":"2025-09-26T16:45:25.237003Z","iopub.status.idle":"2025-09-26T16:45:25.241207Z","shell.execute_reply.started":"2025-09-26T16:45:25.236983Z","shell.execute_reply":"2025-09-26T16:45:25.240565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_test_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)\n\nval_gen = val_test_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)\n\ntest_gen = val_test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:45:27.072255Z","iopub.execute_input":"2025-09-26T16:45:27.072503Z","iopub.status.idle":"2025-09-26T16:45:27.115549Z","shell.execute_reply.started":"2025-09-26T16:45:27.072486Z","shell.execute_reply":"2025-09-26T16:45:27.114706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(train_gen.class_indices)\n\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(128,128,3))\nbase_model.trainable = False  # İlk etapta dondur","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:45:29.813214Z","iopub.execute_input":"2025-09-26T16:45:29.813449Z","iopub.status.idle":"2025-09-26T16:45:30.506589Z","shell.execute_reply.started":"2025-09-26T16:45:29.813433Z","shell.execute_reply":"2025-09-26T16:45:30.506058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    \n    layers.Dense(256, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    \n    layers.Dense(128, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    \n    layers.Dense(num_classes, activation=\"softmax\")\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:45:31.539861Z","iopub.execute_input":"2025-09-26T16:45:31.540106Z","iopub.status.idle":"2025-09-26T16:45:31.586058Z","shell.execute_reply.started":"2025-09-26T16:45:31.540089Z","shell.execute_reply":"2025-09-26T16:45:31.58534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:45:32.610829Z","iopub.execute_input":"2025-09-26T16:45:32.611043Z","iopub.status.idle":"2025-09-26T16:45:32.618954Z","shell.execute_reply.started":"2025-09-26T16:45:32.611027Z","shell.execute_reply":"2025-09-26T16:45:32.618322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\nlr_schedule = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n\n\nhistory = model.fit(\n    train_gen,\n    epochs=20,\n    validation_data=val_gen,\n    callbacks=[early_stop, lr_schedule]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:45:37.327543Z","iopub.execute_input":"2025-09-26T16:45:37.327824Z","iopub.status.idle":"2025-09-26T16:58:17.783669Z","shell.execute_reply.started":"2025-09-26T16:45:37.327804Z","shell.execute_reply":"2025-09-26T16:58:17.783063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-tuning için base_model'i açıyoruz\nbase_model.trainable = True  \n\n# Yeni optimizer tanımla (önceki optimizer'ı kullanma!)\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Fine-tuning eğitim (initial_epoch ile kaldığın yerden devam et)\nhistory_fine = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=30,               # toplam epoch\n    initial_epoch=history.epoch[-1],  # önceki eğitimden kaldığın yerden devam\n    callbacks=[early_stop, lr_schedule]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T16:58:17.785037Z","iopub.execute_input":"2025-09-26T16:58:17.785254Z","iopub.status.idle":"2025-09-26T17:04:42.731138Z","shell.execute_reply.started":"2025-09-26T16:58:17.785237Z","shell.execute_reply":"2025-09-26T17:04:42.730502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss, acc = model.evaluate(test_gen)\nprint(\"Test Accuracy:\", acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T17:04:42.732115Z","iopub.execute_input":"2025-09-26T17:04:42.732392Z","iopub.status.idle":"2025-09-26T17:04:49.033549Z","shell.execute_reply.started":"2025-09-26T17:04:42.732372Z","shell.execute_reply":"2025-09-26T17:04:49.03293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T17:13:47.285656Z","iopub.execute_input":"2025-09-26T17:13:47.285978Z","iopub.status.idle":"2025-09-26T17:13:47.290049Z","shell.execute_reply.started":"2025-09-26T17:13:47.285959Z","shell.execute_reply":"2025-09-26T17:13:47.289104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2 # %20 validation\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T17:13:48.317212Z","iopub.execute_input":"2025-09-26T17:13:48.317483Z","iopub.status.idle":"2025-09-26T17:13:48.32153Z","shell.execute_reply.started":"2025-09-26T17:13:48.317463Z","shell.execute_reply":"2025-09-26T17:13:48.320729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    dataset_path,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\nval_generator = train_datagen.flow_from_directory(\n    dataset_path,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False\n)\n\n# Pretrained Model: MobileNetV2\nbase_model = MobileNetV2(input_shape=(128,128,3), include_top=False, weights=\"imagenet\")\nbase_model.trainable = False  # önce sadece üst katmanları eğitelim\n\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dropout(0.4),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dropout(0.3),\n    layers.Dense(train_generator.num_classes, activation=\"softmax\")\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\"])\n\n\nearly_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True)\n\n\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=20,\n    callbacks=[early_stop, checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T17:13:50.398939Z","iopub.execute_input":"2025-09-26T17:13:50.399381Z","iopub.status.idle":"2025-09-26T17:39:18.236334Z","shell.execute_reply.started":"2025-09-26T17:13:50.399351Z","shell.execute_reply":"2025-09-26T17:39:18.235704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss, acc = model.evaluate(val_generator)\nprint(\"Validation/Test Accuracy:\", acc)\nprint(\"Validation/Test Loss:\", loss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T17:39:18.237778Z","iopub.execute_input":"2025-09-26T17:39:18.237995Z","iopub.status.idle":"2025-09-26T17:39:43.589487Z","shell.execute_reply.started":"2025-09-26T17:39:18.237978Z","shell.execute_reply":"2025-09-26T17:39:43.588868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy & Loss grafikleri\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label=\"Train Acc\")\nplt.plot(history.history['val_accuracy'], label=\"Val Acc\")\nplt.legend()\nplt.title(\"Accuracy\")\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label=\"Train Loss\")\nplt.plot(history.history['val_loss'], label=\"Val Loss\")\nplt.legend()\nplt.title(\"Loss\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T17:39:43.59022Z","iopub.execute_input":"2025-09-26T17:39:43.590471Z","iopub.status.idle":"2025-09-26T17:39:43.89599Z","shell.execute_reply.started":"2025-09-26T17:39:43.590447Z","shell.execute_reply":"2025-09-26T17:39:43.895205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = val_generator.classes\ny_pred = np.argmax(model.predict(val_generator), axis=1)\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10,8))\nsns.heatmap(cm, annot=False, cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T15:58:22.118345Z","iopub.execute_input":"2025-09-26T15:58:22.118582Z","iopub.status.idle":"2025-09-26T15:58:50.124394Z","shell.execute_reply.started":"2025-09-26T15:58:22.118565Z","shell.execute_reply":"2025-09-26T15:58:50.123724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}